{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\n",
    "#from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed for 0.mp4\n",
      "Noise reduction completed for 1.mp4\n",
      "Noise reduction completed for 10.mp4\n",
      "Noise reduction completed for 2.mp4\n",
      "Noise reduction completed for 3.mp4\n",
      "Noise reduction completed for 4.mp4\n",
      "Noise reduction completed for 5.mp4\n",
      "Noise reduction completed for 6.mp4\n",
      "Noise reduction completed for 7.mp4\n",
      "Noise reduction completed for 8.mp4\n",
      "Noise reduction completed for 9.mp4\n",
      "Noise reduction completed for box.mp4\n",
      "Noise reduction completed for fun.mp4\n",
      "Noise reduction completed for good.mp4\n",
      "Noise reduction completed for grow.mp4\n",
      "Noise reduction completed for hero.mp4\n",
      "Noise reduction completed for trust.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def reduce_noise(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".mp4\"):  # Assuming all files are videos\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "            # Create VideoWriter object\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "            # Process each frame\n",
    "            for _ in range(frame_count):\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    # Apply Gaussian blur for noise reduction\n",
    "                    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "                    out.write(blurred_frame)\n",
    "\n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            out.release()\n",
    "\n",
    "            print(f\"Noise reduction completed for {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\Dataset2.0\"\n",
    "output_folder = \"C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\Noise reduction\\\\output\"\n",
    "reduce_noise(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each video file in the folder\n",
    "    for filename in os.listdir(video_folder):\n",
    "        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n",
    "            video_path = os.path.join(video_folder, filename)\n",
    "            video_name = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Create a subfolder for each video\n",
    "            video_output_folder = os.path.join(output_folder, video_name)\n",
    "            if not os.path.exists(video_output_folder):\n",
    "                os.makedirs(video_output_folder)\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = 0\n",
    "\n",
    "            # Read and process each frame\n",
    "            while(cap.isOpened()):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Perform your processing here to identify words and numbers in the frame\n",
    "                # For simplicity, let's just save every 16th frame\n",
    "                if frame_count % 16 == 0:\n",
    "                    output_frame_path = os.path.join(video_output_folder, f\"{video_name}_frame_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(output_frame_path, frame)\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "# Example usage:\n",
    "video_dataset_folder = \"C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\Noise reduction\\\\output\"\n",
    "output_frames_folder = \"C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\Frames\"\n",
    "extract_frames(video_dataset_folder, output_frames_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Normal Frames into GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "def glcm_noise_reduction(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the GLCM of the grayscale image\n",
    "    glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    # Compute the mean of the GLCM\n",
    "    mean_glcm = np.mean(glcm)\n",
    "\n",
    "    # Subtract the mean from the original image to reduce noise\n",
    "    reduced_noise_image = gray - mean_glcm\n",
    "\n",
    "    return reduced_noise_image\n",
    "\n",
    "# Specify the directory containing the folders with frames\n",
    "root_dir = 'C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\Frames'\n",
    "\n",
    "# Create a new folder to save all the noise-reduced images\n",
    "new_root_dir = 'C:\\\\Users\\\\sumit\\\\OneDrive\\\\Desktop\\\\output_denoised_image_folder'\n",
    "\n",
    "# Loop over each folder (video)\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    new_folder_path = os.path.join(new_root_dir, folder)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    # Loop over each image (frame) in the folder\n",
    "    for frame in os.listdir(folder_path):\n",
    "        frame_path = os.path.join(folder_path, frame)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(frame_path)\n",
    "\n",
    "        # Apply GLCM noise reduction\n",
    "        reduced_noise_image = glcm_noise_reduction(image)\n",
    "\n",
    "        # Save the noise-reduced image in the new folder\n",
    "        cv2.imwrite(os.path.join(new_folder_path, frame), reduced_noise_image)\n",
    "\n",
    "print('Noise reduction completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 images belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 images belonging to 17 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ksaqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 94, 70, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 47, 35, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 33, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 22, 16, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 10, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 5, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 904337 (3.45 MB)\n",
      "Trainable params: 904337 (3.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 17\n",
    "TRAIN_DATA_DIR = \"D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Define data generator\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time=time.time()\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the computational time\n",
    "comp_time = end_time - start_time\n",
    "\n",
    "model.save('cnnown1.h5')\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "\n",
    "print(f'Training Accuracy: {train_acc * 100}')\n",
    "print(f'Validation Accuracy: {val_acc * 100}')\n",
    "print(f'Trainig time: {comp_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 298 images belonging to 17 classes.\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create an ImageDataGenerator object\n",
    "# datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Create a generator\n",
    "# generator = datagen.flow_from_directory(\n",
    "#     'D:\\\\New Dataset Lip Movement Projec\\\\FINAL YEAR PROJECT\\\\output_denoised_image_folder',\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=16,\n",
    "#     class_mode='binary'\n",
    "# )\n",
    "\n",
    "# print(generator.batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
