{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\n",
    "#from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# noise reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed for 0.mp4\n",
      "Noise reduction completed for 1.mp4\n",
      "Noise reduction completed for 10.mp4\n",
      "Noise reduction completed for 2.mp4\n",
      "Noise reduction completed for 3.mp4\n",
      "Noise reduction completed for 4.mp4\n",
      "Noise reduction completed for 5.mp4\n",
      "Noise reduction completed for 6.mp4\n",
      "Noise reduction completed for 7.mp4\n",
      "Noise reduction completed for 8.mp4\n",
      "Noise reduction completed for 9.mp4\n",
      "Noise reduction completed for box.mp4\n",
      "Noise reduction completed for fun.mp4\n",
      "Noise reduction completed for good.mp4\n",
      "Noise reduction completed for grow.mp4\n",
      "Noise reduction completed for hero.mp4\n",
      "Noise reduction completed for trust.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def reduce_noise(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".mp4\"):  # Assuming all files are videos\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "            # Create VideoWriter object\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "            # Process each frame\n",
    "            for _ in range(frame_count):\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    # Apply Gaussian blur for noise reduction\n",
    "                    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "                    out.write(blurred_frame)\n",
    "\n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            out.release()\n",
    "\n",
    "            print(f\"Noise reduction completed for {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\New Female Dataset\"\n",
    "output_folder = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output\"\n",
    "reduce_noise(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def extract_frames(video_folder, output_folder, num_frames=8):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each video file in the folder\n",
    "    for filename in os.listdir(video_folder):\n",
    "        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n",
    "            video_path = os.path.join(video_folder, filename)\n",
    "            video_name = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Create a subfolder for each video\n",
    "            video_output_folder = os.path.join(output_folder, video_name)\n",
    "            if not os.path.exists(video_output_folder):\n",
    "                os.makedirs(video_output_folder)\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            # Get the total number of frames in the video\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "            # Calculate the frame interval to get exactly num_frames frames\n",
    "            frame_interval = max(1, total_frames // num_frames)\n",
    "\n",
    "            frame_count = 0\n",
    "\n",
    "            # Read and process each frame\n",
    "            while(cap.isOpened() and frame_count < num_frames):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Save the frame\n",
    "                output_frame_path = os.path.join(video_output_folder, f\"{video_name}_frame_{frame_count}.jpg\")\n",
    "                cv2.imwrite(output_frame_path, frame)\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # Move to the next frame based on the calculated interval\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "# Example usage:\n",
    "video_dataset_folder = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output\"\n",
    "output_frames_folder = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\Frames\"\n",
    "extract_frames(video_dataset_folder, output_frames_folder, num_frames=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to glcm frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "def glcm_noise_reduction(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the GLCM of the grayscale image\n",
    "    glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    # Compute the mean of the GLCM\n",
    "    mean_glcm = np.mean(glcm)\n",
    "\n",
    "    # Subtract the mean from the original image to reduce noise\n",
    "    reduced_noise_image = gray - mean_glcm\n",
    "\n",
    "    return reduced_noise_image\n",
    "\n",
    "# Specify the directory containing the folders with frames\n",
    "root_dir = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\Frames\"\n",
    "\n",
    "# Create a new folder to save all the noise-reduced images\n",
    "new_root_dir = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Loop over each folder (video)\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    new_folder_path = os.path.join(new_root_dir, folder)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    # Loop over each image (frame) in the folder\n",
    "    for frame in os.listdir(folder_path):\n",
    "        frame_path = os.path.join(folder_path, frame)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(frame_path)\n",
    "\n",
    "        # Apply GLCM noise reduction\n",
    "        reduced_noise_image = glcm_noise_reduction(image)\n",
    "\n",
    "        # Save the noise-reduced image in the new folder\n",
    "        cv2.imwrite(os.path.join(new_folder_path, frame), reduced_noise_image)\n",
    "\n",
    "print('Noise reduction completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation ResnetMobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_5.h5'],\n",
    "\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5'],\n",
    "\n",
    "    ['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobile\\\\resnetMobile_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobile\\\\resnetMobile_kfold(1)_2.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobile\\\\resnetMobile_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobile\\\\resnetMobile_kfold(1)_4.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobile\\\\resnetMobile_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['4', '4', '4', '8', '4', '4', '4', 'box', '4', 'box', '10', 'box', 'box', 'box', 'box', 'box', 'box', '4', '4', '4', 'box', 'box', '3', '3', '3', 'box', '8', '4', '4', '3', 'box', 'box', '3', 'box', '4', 'box', '4', '4', '4', '4', 'box', 'box', '4', '4', 'box', 'box', 'box', 'box', 'fun', 'box', 'box', '3', '4', '4', '4', 'fun', '8', '8', 'box', '4', '4', '4', '4', '4', 'fun', '10', 'box', 'box', '4', 'box', 'box', 'box', 'box', 'box', 'box', '4', 'box', '3', '4', 'box', '3', '8', '8', '8', '4', 'box', 'box', '4', '3', '4', 'hero', 'box', '4', '4', '4', 'box', '4', '8', 'box', '8', '4', '4', 'box', '4', '4', '10', '8', 'box', 'box', '3', '4', 'box', '3', 'box', '8', '4', '4', '4', 'box', 'box', 'box', 'box', '8', '5', '8', '4', 'trust', 'box', '4', '10', '8', '4', '4', '4', '4', '4']\n",
      "Test Accuracy: 3.6764705882352944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_5.h5'],\n",
    "\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5'],\n",
    "\n",
    "    ['D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\CNN\\\\own\\\\cnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\CNN\\\\own\\\\cnn_kfold(1)_2.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\CNN\\\\own\\\\cnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\CNN\\\\own\\\\cnn_kfold(1)_4.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\CNN\\\\own\\\\cnn_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['7', 'hero', '3', '1', 'box', 'box', '4', '4', 'trust', '4', '4', '10', '6', 'grow', '4', '1', '10', '10', '6', '6', '4', '4', '7', 'hero', 'hero', '3', 'trust', 'box', 'box', '4', '4', '4', '7', 'hero', 'box', '4', '8', '0', '3', '6', 'box', '4', '4', 'box', '6', 'box', 'box', '4', 'hero', '4', '9', 'hero', 'box', 'grow', 'grow', 'grow', '10', '6', '3', '3', 'trust', '6', '4', '4', 'grow', '10', '4', '4', '4', '4', '4', 'box', 'box', '4', '4', '4', '4', '4', '0', '6', 'hero', 'hero', '4', 'fun', 'hero', 'hero', 'fun', '9', '7', '3', 'box', 'box', '3', '6', '4', '4', '6', 'fun', '4', 'grow', '10', '4', 'box', 'grow', '0', 'box', 'box', 'good', '4', 'hero', 'trust', 'trust', '7', '3', '10', 'box', '4', 'good', '3', 'trust', '10', '10', 'box', 'box', 'good', 'box', '10', 'box', 'hero', '10', '10', 'trust', '10', 'grow', 'hero', 'hero']\n",
      "Test Accuracy: 11.029411764705882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_5.h5'],\n",
    "\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5'],\n",
    "\n",
    "    ['D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\Resnet\\\\own\\\\resnet_kfold(1)_1.h5','D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\Resnet\\\\own\\\\resnet_kfold(1)_2.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\Resnet\\\\own\\\\resnet_kfold(1)_3.h5','D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\Resnet\\\\own\\\\resnet_kfold(1)_4.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\CrossValidation\\\\Resnet\\\\own\\\\resnet_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['3', 'trust', 'trust', '0', '10', '10', '3', '3', '10', '3', '7', '10', '3', 'fun', '8', '4', '10', '10', '3', '10', 'trust', '3', '4', 'good', 'trust', '3', '3', '3', '5', 'trust', '3', '3', '3', '3', 'box', '3', '3', '3', '8', 'trust', '7', '4', '3', '3', '3', '3', 'box', '3', 'trust', '3', '1', '10', '3', 'box', '0', '4', 'box', '0', '3', '0', '3', '1', '3', '3', 'trust', '10', '0', '3', 'trust', 'trust', 'trust', '10', '1', '3', 'trust', '3', '4', '3', 'trust', '8', 'trust', '4', '4', '4', 'box', '4', 'trust', '4', '3', '3', '10', '3', '8', '3', '3', 'trust', '8', '3', 'trust', '7', '3', '3', '3', 'trust', 'trust', '1', 'box', '3', '3', 'trust', 'trust', 'trust', 'trust', '3', '10', '3', '0', 'trust', '0', 'fun', '10', '10', '10', '3', '3', '10', '10', '3', '8', 'box', '10', '10', '3', '4', 'fun', 'fun']\n",
      "Test Accuracy: 8.088235294117647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResnetMobile_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_5.h5'],\n",
    "\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5'],\n",
    "\n",
    "    ['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobileVGG\\\\resnetMobile-vgg_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobileVGG\\\\resnetMobile-vgg_kfold(1)_2.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobileVGG\\\\resnetMobile-vgg_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobileVGG\\\\resnetMobile-vgg_kfold(1)_4.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\ResnetMobileVGG\\\\resnetMobile-vgg_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['4', '4', '4', 'box', '4', '4', '4', 'box', '3', 'box', 'fun', 'box', '3', 'box', 'box', 'box', '4', '4', 'fun', 'fun', 'box', 'box', '4', '4', '3', '4', '4', '4', '4', 'box', 'box', 'box', '4', 'box', '8', 'box', 'fun', 'fun', 'fun', 'fun', 'box', 'box', '4', '3', 'box', 'box', 'box', 'box', '5', 'box', 'box', '4', '10', '4', 'fun', 'fun', '1', 'box', 'box', '4', 'fun', '5', '3', 'fun', 'fun', '4', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', '4', 'box', '4', '4', 'box', '4', 'good', 'fun', 'fun', 'fun', '4', '4', '4', 'fun', '4', '10', '4', '3', '0', 'fun', 'box', '4', 'fun', 'box', '10', '3', 'box', 'box', '5', '4', 'hero', '5', 'box', 'box', '4', '5', 'box', '4', '4', '10', '4', '3', '4', '4', 'box', 'box', 'box', '3', '5', '10', '4', '4', '4', '4', 'fun', 'hero', 'fun', '3', 'fun', '4', '4']\n",
      "Test Accuracy: 2.941176470588235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG\\\\VGG_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['4', '4', '4', 'box', '4', '4', '4', 'box', '3', 'box', 'fun', 'box', '3', 'box', 'box', 'box', '4', '4', 'fun', 'fun', 'box', 'box', '4', '4', '3', '4', '4', '4', '4', 'box', 'box', 'box', '4', 'box', '8', 'box', 'fun', 'fun', 'fun', 'fun', 'box', 'box', '4', '3', 'box', 'box', 'box', 'box', '5', 'box', 'box', '4', '10', '4', 'fun', 'fun', '1', 'box', 'box', '4', 'fun', '5', '3', 'fun', 'fun', '4', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', '4', 'box', '4', '4', 'box', '4', 'good', 'fun', 'fun', 'fun', '4', '4', '4', 'fun', '4', '10', '4', '3', '0', 'fun', 'box', '4', 'fun', 'box', '10', '3', 'box', 'box', '5', '4', 'hero', '5', 'box', 'box', '4', '5', 'box', '4', '4', '10', '4', '3', '4', '4', 'box', 'box', 'box', '3', '5', '10', '4', '4', '4', '4', 'fun', 'hero', 'fun', '3', 'fun', '4', '4']\n",
      "Test Accuracy: 2.941176470588235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    #['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_2.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5',\n",
    "    # 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS\\\\CNN_RNN\\\\cnn-rnn_kfold(1)_4.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['4', '4', '4', 'box', '4', '4', '4', 'box', '3', 'box', 'fun', 'box', '3', 'box', 'box', 'box', '4', '4', 'fun', 'fun', 'box', 'box', '4', '4', '3', '4', '4', '4', '4', 'box', 'box', 'box', '4', 'box', '8', 'box', 'fun', 'fun', 'fun', 'fun', 'box', 'box', '4', '3', 'box', 'box', 'box', 'box', '5', 'box', 'box', '4', '10', '4', 'fun', 'fun', '1', 'box', 'box', '4', 'fun', '5', '3', 'fun', 'fun', '4', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', '4', 'box', '4', '4', 'box', '4', 'good', 'fun', 'fun', 'fun', '4', '4', '4', 'fun', '4', '10', '4', '3', '0', 'fun', 'box', '4', 'fun', 'box', '10', '3', 'box', 'box', '5', '4', 'hero', '5', 'box', 'box', '4', '5', 'box', '4', '4', '10', '4', '3', '4', '4', 'box', 'box', 'box', '3', '5', '10', '4', '4', '4', '4', 'fun', 'hero', 'fun', '3', 'fun', '4', '4']\n",
      "Test Accuracy: 2.941176470588235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_paths = [\n",
    "    ['D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG_lstm\\\\VGG-lstm_kfold(1)_1.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG_lstm\\\\VGG-lstm_kfold(1)_2.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG_lstm\\\\VGG-lstm_kfold(1)_3.h5', 'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG_lstm\\\\VGG-lstm_kfold(1)_4.h5',\n",
    "     'D:\\\\FINAL MAJOR20-2\\\\ALL MODELS 2\\\\VGG_lstm\\\\VGG-lstm_kfold(1)_5.h5'],\n",
    "    # Add paths for other models similarly\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fold_paths in model_paths:\n",
    "    model_fold = []\n",
    "    for model_path in model_fold_paths:\n",
    "        model = load_model(model_path)\n",
    "        model_fold.append(model)\n",
    "    models.append(model_fold)\n",
    "#model2 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG16\\\\vgg.h5')\n",
    "#model3 = load_model('D:\\\\FINAL MAJOR20-2\\\\CNN_RNN\\\\cnn_rnn100.h5')\n",
    "#model4 = load_model('D:\\\\FINAL MAJOR20-2\\\\resnet\\\\resnet.h5')\n",
    "#model5 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile\\\\resnetMobile.h5')\n",
    "#model6 = load_model('D:\\\\FINAL MAJOR20-2\\\\ResnetMobile_VGG\\\\resnetMobile_vgg_combined.h5')\n",
    "#model7 = load_model('D:\\\\FINAL MAJOR20-2\\\\VGG-lstm\\\\vgg-lstm.h5')\n",
    "#model8 = load_model('D:\\\\FINAL MAJOR20-2\\\\GLCM-LSTM\\\\kaggleDataset\\\\before_Kfold\\\\GLCM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 images belonging to 17 classes.\n",
      "Class Labels:\n",
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'box', 'fun', 'good', 'grow', 'hero', 'trust']\n",
      "Numeric Labels:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "True Labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '10', '10', '10', '10', '10', '10', '10', '10', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7', '7', '7', '7', '7', '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9', '9', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'fun', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'grow', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'hero', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust', 'trust']\n",
      "Predicted Labels:\n",
      "['8', '9', 'box', '4', '8', '8', '8', '8', '8', '8', '3', '8', '8', '8', '8', '8', 'box', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', 'box', '5', '8', '8', '8', '8', '8', '8', '4', '8', '8', '8', '8', '8', '8', '8', '8', 'box', '8', '8', '8', '8', '8', 'box', 'box', 'box', 'box', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '5', '5', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', 'box', 'box', 'box', '8', 'box', '8', '8', '8', '8', '8', '8', '8', '5', '8', '8', '8', '8', '8', '8', '8', '8', 'box', '8', '4', '8', '3', '3', '8', '8', '4', '4', 'box', '8', '8', '8', '8', '4', 'box', '8', 'box', 'box', '8', '1']\n",
      "Test Accuracy: 7.352941176470589\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (96, 72)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 18\n",
    "TRAIN_DATA_DIR = \"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\"\n",
    "\n",
    "# Create a new data generator for the test data\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\sumit\\\\Downloads\\\\Noise reduction 1\\\\output_denoised_image_folder\",  # Specify the directory argument\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=1,  # Use batch size 1 for single image prediction\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of samples in the test set\n",
    "num_test_samples = test_generator.samples\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = model.predict(test_generator, steps=num_test_samples)\n",
    "\n",
    "# Get the ground truth labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert class labels to numeric labels\n",
    "numeric_labels = [test_generator.class_indices[label] for label in class_labels]\n",
    "\n",
    "# Map numeric labels to class labels\n",
    "numeric_to_label = dict(zip(numeric_labels, class_labels))\n",
    "\n",
    "# Map numeric predictions to class labels\n",
    "y_pred_labels = [numeric_to_label[label] for label in y_pred_classes]\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "y_true_labels = [numeric_to_label[label] for label in y_true]\n",
    "\n",
    "# Display the class labels and their numeric mappings\n",
    "print(\"Class Labels:\")\n",
    "print(class_labels)\n",
    "print(\"Numeric Labels:\")\n",
    "print(numeric_labels)\n",
    "\n",
    "# Display the true and predicted labels for the test set\n",
    "print(\"True Labels:\")\n",
    "print(y_true_labels)\n",
    "print(\"Predicted Labels:\")\n",
    "print(y_pred_labels)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_acc = np.sum(y_pred_classes == y_true) / num_test_samples\n",
    "print(f'Test Accuracy: {test_acc * 100}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
